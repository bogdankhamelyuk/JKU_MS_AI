{"cells":[{"cell_type":"markdown","metadata":{"id":"5G_CeTI0QVnW"},"source":["# Installation of important packages and imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjrOVfytSRGN","outputId":"3c4194df-9421-442f-dae5-b6de66ca28e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting labelbox\n","  Downloading labelbox-3.34.0-py3-none-any.whl (185 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.5/185.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.8/dist-packages (from labelbox) (2.25.1)\n","Requirement already satisfied: google-api-core>=1.22.1 in /usr/local/lib/python3.8/dist-packages (from labelbox) (2.11.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from labelbox) (4.64.1)\n","Collecting backoff==1.10.0\n","  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n","Collecting ndjson\n","  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n","Requirement already satisfied: pydantic<2.0,>=1.8 in /usr/local/lib/python3.8/dist-packages (from labelbox) (1.10.2)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core>=1.22.1->labelbox) (1.57.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-api-core>=1.22.1->labelbox) (3.19.6)\n","Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.8/dist-packages (from google-api-core>=1.22.1->labelbox) (2.15.0)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2.0,>=1.8->labelbox) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->labelbox) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->labelbox) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->labelbox) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.22.0->labelbox) (1.24.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core>=1.22.1->labelbox) (5.2.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core>=1.22.1->labelbox) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core>=1.22.1->labelbox) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core>=1.22.1->labelbox) (0.2.8)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core>=1.22.1->labelbox) (0.4.8)\n","Installing collected packages: ndjson, backoff, labelbox\n","Successfully installed backoff-1.10.0 labelbox-3.34.0 ndjson-0.3.1\n"]}],"source":["!pip install labelbox"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dje6fFllHpTI","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"outputId":"4aadeff3-69a7-45d4-e413-dafe370c2615"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting av\n","  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-10.0.0\n"]}],"source":["!pip install av"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GCAWaP6eSOAS","outputId":"3e5d2b09-3956-4193-8628-fd4ac9d15d52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from labelbox import Client\n","import requests, ndjson, json, math\n","import torch, torchvision, os, random\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np \n","import time \n","from google.colab import drive\n","drive.mount('/content/drive') "]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007958529},"id":"f1xbJyy4HpTL","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["path = \"/content/drive/MyDrive/labels/\"\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQiGbfqmJoWm","outputId":"73db2bc0-1998-4426-b8c3-a252b72467da"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007958588},"id":"P_kbJCw7HpTL","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def count_all_jsons(): \n","    total_json_number = 0\n","    for file in os.listdir(path):\n","        if file.endswith('.json'):\n","            total_json_number+=1\n","    return total_json_number"]},{"cell_type":"markdown","metadata":{"id":"fySroXpQQczi"},"source":["# Creating dataset for retrieving random samples for test and training cases"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007958709},"id":"pkzPGlv5HpTL","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["class DroneThrmImg_Dataset(Dataset):\n","    # create arrays, where random and non-repeating numbers of videos in the working directory will be stored \n","    train_file_names, test_file_names = [], [] \n","    random.seed(10)\n","\n","    def __init__(self,req_samples_number, dataset_type):\n","        self.dataset_type = dataset_type\n","        self.total_json_number = count_all_jsons()\n","\n","        # api for labelbox\n","        self.API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbGJ0bWV6aHQ5eW5vMDgxMDFvcTUyc3QxIiwib3JnYW5pemF0aW9uSWQiOiJjbGJ0bWV6ZmI5eW5uMDgxMGduZGk2OXZtIiwiYXBpS2V5SWQiOiJjbGJ1c2w1eW4ydDRlMDgwbDd6dHYyaTFkIiwic2VjcmV0IjoiNDhiMGYxYTI5NzZiMzFmODFhMmQwMjdhMzQ2ZGFhYTgiLCJpYXQiOjE2NzE0NTQwNTMsImV4cCI6MjMwMjYwNjA1M30.byH8m7_7qZZCxO3SHY14JIS_Xer0JPy5i-WH16DJ5jM\"\n","        # project of labelbox\n","        self.project = Client(api_key=self.API_KEY).get_project('clbtwzgas9u4g070i4kr26byi')\n","        self.export_url = self.project.export_labels()\n","        self.exports = requests.get(self.export_url).json()\n","\n","        if req_samples_number < self.total_json_number:\n","            self.req_samples_number = req_samples_number # number of samples required for training/test dataset and is less than total number of samples\n","        else:\n","            raise IndexError(f\"required samples number ({req_samples_number}) is greater than\\\n"," total number of available samples({self.total_json_number})\")\n","        \n","        if self.dataset_type == 'TEST':\n","            self.random_videos = self.append_random_number(DroneThrmImg_Dataset.test_file_names,self.req_samples_number)\n","\n","        elif self.dataset_type == 'TRAIN':\n","            self.random_videos = self.append_random_number(DroneThrmImg_Dataset.train_file_names,self.req_samples_number)\n","\n","        else:\n","            raise NameError(f\"'{dataset_type}' is not in the list of available dataset types. \\nAvailable types are: 'TEST' and 'TRAIN.\")\n","        \n","\n","    def __len__(self):\n","        return self.req_samples_number # return required number of samples, since that's exactly length of the each dataset\n","\n","    def __getitem__(self, idx):\n","\n","        # prepare videos, which are available in the local directory\n","        video_number = self.random_videos[idx] # take out random generated number of the video, according to its index\n","        video_name = \"video_\" + str(video_number) + \".mp4\"\n","        video_tensor = torchvision.io.read_video(path+video_name)[0] # create video tensor for the output, which shape \n","        _,Height, Width,_= video_tensor.size()\n","        # T,H,W,C = video_tensor.size()\n","        # 0,1,2,3\n","        # 2415, 256, 320, 3 (for example)\n","        gray_video_tensor = video_tensor.narrow(-1,0,1) # narrow last dimension(=channels) to 1\n","        #print(gray_video_tensor.size())\n","        gray_video_tensor = torch.permute(gray_video_tensor,(0,3,1,2))\n","        #print(gray_video_tensor.size())\n","\n","\n","        # extract labels of idx video using labelbox API\n","        # take out url of labeled video\n","        \n","        # 2Do: create txt file where for each video all labeled frames are stored\n","        # F.e.: video\n","        labeled_video_url = self.exports[idx][\"Label\"][\"frames\"]\n","        headers = {\"Authorization\": f\"Bearer {self.API_KEY}\"}\n","        labeled_video = ndjson.loads(requests.get(labeled_video_url, headers=headers).text)\n","\n","        labels = []\n","        for labeled_frame in labeled_video:\n","            # create 16x16x3 grid, in each position of which is\n","            # the prob-ty of recognition and x,y-coordinates of the label to be stored\n","            grid = torch.zeros(16,16,3)             \n","\n","            for objects in labeled_frame['objects']:\n","                x_abs = objects['point']['x']\n","                y_abs = objects['point']['y']\n","     \n","            \n","                x_rel, column  = math.modf(x_abs/16) # calculation of relative horizontal position of label inside of grid\n","                y_rel, row  = math.modf(y_abs/16) # calculation of relative vertical position of label inside of grid\n","      \n","                # fill the grid \n","                grid[int(row)][int(column)][0]=1 # probability that in this grid is person, make it to 100%\n","                grid[int(row)][int(column)][1]=x_rel \n","                grid[int(row)][int(column)][2]=y_rel \n","                labels.append(grid) # append that 16x16x3 gridded frame to the labels\n","        labels = torch.stack(labels)#.to(device=) # convert labels to the torch-type tensor\n","        \n","        # convert tensors to torch float 32 and locate them on device\n","        labels = labels.to(device).to(torch.float32)\n","        gray_video_tensor = gray_video_tensor.to(device).to(torch.float32)\n","\n","        return gray_video_tensor, labels \n","  \n","    def append_random_number(self, optional_list, samples_number):\n","        i = 0\n","        while i < samples_number:\n","            # substract 1 from total_json_number, because the first video is named using 0, not 1, \n","            # so the number of the last video is 1 less then total quantity\n","            r = random.randint(0,self.total_json_number-1) \n","            if not r in DroneThrmImg_Dataset.train_file_names \\\n","                        and not r in DroneThrmImg_Dataset.test_file_names:\n","                optional_list.append(r)\n","                i+=1\n","        return optional_list"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007958815},"id":"X9_P0O8wHpTM","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["all_files = count_all_jsons()\n","train_files = int(0.8*all_files)\n","test_files = int(0.2*all_files)\n","\n","test_dataset = DroneThrmImg_Dataset(req_samples_number=test_files,  dataset_type='TEST')\n","train_dataset = DroneThrmImg_Dataset(req_samples_number=train_files, dataset_type='TRAIN')"]},{"cell_type":"markdown","metadata":{"id":"g_nZN11OQlNi"},"source":["# Creating simple architecture "]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007958894},"id":"aI9DQL-aHpTN","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["class myCNN:\n","    def __init__(self, input_channels):\n","        self.input_channels = input_channels\n","\n","        self.model = torch.nn.Sequential(\n","            self.network()\n","        ).to(device)\n","        \n","        self.loss_fn = torch.nn.BCELoss()\n","        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=1e-5, momentum=0.9)\n","        \n","    def get_model(self):\n","        return self.model, self.loss_fn, self.optimizer\n","\n","    def network(self):\n","        return torch.nn.Sequential(\n","            torch.nn.Conv2d(1,32, kernel_size=(7,11),stride=1), # = 250,310\n","            torch.nn.Conv2d(32,64, kernel_size=11,stride=2), # 120,150\n","            torch.nn.MaxPool2d(3), # 40,50\n","            torch.nn.Conv2d(64,128,kernel_size=2,stride=2), # 20,25\n","            torch.nn.Conv2d(128,128,kernel_size=(5,10),stride=1), # 16,16\n","            torch.nn.ReLU(), # 16,16\n","            torch.nn.Flatten(start_dim=0),\n","            torch.nn.Linear(32768,16*16*3),\n","            torch.nn.Sigmoid()\n","    )\n","    \n","    def get_train_data(self):\n","        train_dataloader = DataLoader(train_dataset,shuffle=True)\n","        return train_dataloader\n","    def get_test_data(self):\n","        test_dataloader = DataLoader(test_dataset,shuffle=True)\n","        return test_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007960240},"id":"XzQH7HkrHpTN","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["my_cnn = myCNN(input_channels=1)\n","model, loss, optimizer = my_cnn.get_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007960295},"id":"NqOImiPuHpTN","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["def train_batch(video, label, model, opt, loss_fn):\n","    label = torch.flatten(label)\n","    model.train() # <- let's hold on to this until we reach\n","    # dropout section\n","    # call your model like any python function on your batch # of inputs\n","    predicted_label = model(video)\n","    # compute loss\n","    batch_loss = loss_fn(predicted_label, label)\n","    \n","    # based on the forward pass in `model(x)` compute all the # gradients of 'model.parameters()'\n","    batch_loss.backward()\n","    # apply new-weights = f(old-weights, old-weight-gradients) # where \"f\" is the optimizer\n","    optimizer.step()\n","    # Flush gradients memory for next batch of calculations optimizer.zero_grad()\n","    optimizer.zero_grad()\n","    return batch_loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007960391},"id":"g5yGTVm_HpTO","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["@torch.no_grad()\n","def accuracy(frame, labeled_frame, model):\n","    labeled_frame = torch.flatten(labeled_frame)\n","\n","    prediction = model(frame)\n","    is_correct = (prediction > 0.5) == labeled_frame\n","    return is_correct.cpu().numpy().tolist()\n","\n","@torch.no_grad()\n","def test_loss(frame, labeled_frame, model):\n","    labeled_frame = torch.flatten(labeled_frame)\n","    prediction = model(frame)\n","    test_loss = loss(prediction, labeled_frame)\n","    return test_loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"gather":{"logged":1673007960440},"id":"VSUpBUdIHpTO","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["train_losses, train_accuracies = [], []\n","test_losses, test_accuracies = [], []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"gather":{"logged":1673007967081},"id":"gmtijO09HpTO","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"outputId":"945a249b-c3db-45cb-c696-2f7d68fa46d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["************************\n","epoch:  0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torchvision/io/video.py:162: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"name":"stdout","output_type":"stream","text":["train epoch loss:  0.14441266554520213\n","test epoch loss:  0.041536322451345545\n","************************\n","epoch:  1\n","train epoch loss:  0.010231154504419035\n","test epoch loss:  0.03237616234166866\n","************************\n","epoch:  2\n","train epoch loss:  0.010464770082161129\n","test epoch loss:  0.027534662282341093\n","************************\n","epoch:  3\n","train epoch loss:  0.010459988488523161\n","test epoch loss:  0.023597730925676137\n","************************\n","epoch:  4\n","train epoch loss:  0.009896969652238843\n","test epoch loss:  0.023329797653160483\n","************************\n","epoch:  5\n","train epoch loss:  0.009553517933994768\n","test epoch loss:  0.021734659783842585\n","************************\n","epoch:  6\n","train epoch loss:  0.009428016479626293\n","test epoch loss:  0.02063124922865474\n","************************\n","epoch:  7\n","train epoch loss:  0.00896282617075328\n","test epoch loss:  0.021335220934826992\n","************************\n","epoch:  8\n","train epoch loss:  0.00879524973438369\n","test epoch loss:  0.01887172108283426\n","************************\n","epoch:  9\n","train epoch loss:  0.00847900820342181\n","test epoch loss:  0.019638345651865497\n","training time:  5425.998963594437\n"]}],"source":["start = time.time()\n","for epoch in range(10):\n","    print(\"************************\")\n","    print(\"epoch: \", epoch)\n","\n","    train_dataloader = my_cnn.get_train_data()\n","    test_dataloader = my_cnn.get_test_data()\n","\n","    train_epoch_losses = []\n","    test_epoch_losses = []\n","\n","    for i, batch in enumerate(iter(train_dataloader)):\n","        video, label = batch\n","        video = video[0]\n","        label = label[0]\n","        for frame, labeled_frame in zip(video,label):\n","            batch_loss = train_batch(frame, labeled_frame, model, optimizer, loss)\n","            train_epoch_losses.append(batch_loss)\n","\n","    for i, batch in enumerate(iter(test_dataloader)):\n","        video, label = batch\n","        video = video[0]\n","        label = label[0]\n","        for frame, labeled_frame in zip(video,label):\n","            testing_loss = test_loss(frame, labeled_frame, model)\n","            test_epoch_losses.append(testing_loss)\n","        \n","    print(\"train epoch loss: \", np.array(train_epoch_losses).mean())\n","    print(\"test epoch loss: \", np.array(test_epoch_losses).mean())\n","    train_losses.append(np.array(train_epoch_losses).mean())\n","    test_losses.append(np.array(test_epoch_losses).mean())\n","\n","end = time.time()\n","print(\"training time: \",end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"gather":{"logged":1673007961361},"id":"ri_WUUJVHpTO","jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}},"outputId":"a17f60ef-982f-4631-e03d-d7879bec16b0"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["epochs = np.arange(10)+1\n","\n","import matplotlib.ticker as mtick\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mticker\n","# %matplotlib inline\n","plt.plot(epochs, test_losses, 'bo',label='Test losses')\n","\n","plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n","plt.title('Test losses')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) \\\n","                           for x in plt.gca().get_yticks()])\n","plt.legend()\n","plt.grid('off')\n","plt.show()\n","\n","torch.save(model.state_dict(), f=\"/content/drive/MyDrive/labels/\"+\"cv_project_1st_sem.pth\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernel_info":{"name":"python38-azureml-pt-tf"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.6 (v3.10.6:9c7b4bd164, Aug  1 2022, 17:13:48) [Clang 13.0.0 (clang-1300.0.29.30)]"},"microsoft":{"host":{"AzureML":{"notebookHasBeenCompleted":true}}},"nteract":{"version":"nteract-front-end@1.0.0"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
